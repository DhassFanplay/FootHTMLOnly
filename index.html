<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Foot Detection with Debug Dot</title>
  <style>
    body {
      margin: 0;
      background: #111;
      overflow: hidden;
      color: white;
      font-family: sans-serif;
    }

    canvas, video {
      position: absolute;
      top: 0;
      left: 0;
    }

    #captureButton {
      position: absolute;
      top: 10px;
      left: 10px;
      z-index: 100;
      padding: 10px 20px;
      font-size: 16px;
      background: #00aaff;
      border: none;
      border-radius: 4px;
      color: white;
      cursor: pointer;
    }

    #status {
      position: absolute;
      top: 10px;
      right: 10px;
      padding: 10px;
      background: #333;
      border-radius: 4px;
      z-index: 100;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <button id="captureButton">Capture Foot</button>
  <div id="status">Waiting for capture...</div>

  <script async src="https://docs.opencv.org/4.9.0/opencv.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const captureButton = document.getElementById('captureButton');
    const statusDiv = document.getElementById('status');

    let template = null;
    let resizedTemplate = null;
    let templateSize = 150;
    const scale = 0.5; // Resize factor for faster processing
    const minMatchScore = 0.5;

    async function startCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: {
                facingMode: { ideal: 'environment' } // Prefer back camera
            }
        });
      video.srcObject = stream;

      return new Promise(resolve => {
        video.onloadedmetadata = () => {
          video.width = canvas.width = video.videoWidth;
          video.height = canvas.height = video.videoHeight;
          resolve();
        };
      });
    }

    function waitForOpenCV() {
      return new Promise(resolve => {
        const check = () => {
          if (cv && cv.Mat) resolve();
          else setTimeout(check, 100);
        };
        check();
      });
    }

    function drawFootDot(x, y) {
      ctx.beginPath();
      ctx.arc(x, y, 10, 0, 2 * Math.PI);
      ctx.fillStyle = 'red';
      ctx.fill();
    }

    function captureTemplate() {
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = video.videoWidth;
      tempCanvas.height = video.videoHeight;
      const tempCtx = tempCanvas.getContext('2d');

      tempCtx.drawImage(video, 0, 0);
      const centerX = Math.floor(video.videoWidth / 2);
      const centerY = Math.floor(video.videoHeight / 2);
      const startX = centerX - templateSize / 2;
      const startY = centerY - templateSize / 2;

      const imageData = tempCtx.getImageData(startX, startY, templateSize, templateSize);
      template = cv.matFromImageData(imageData);
      cv.cvtColor(template, template, cv.COLOR_RGBA2GRAY);

      // Resize template for matching
      resizedTemplate = new cv.Mat();
      cv.resize(template, resizedTemplate, new cv.Size(0, 0), scale, scale, cv.INTER_AREA);

      statusDiv.textContent = "‚úÖ Foot captured!";
      console.log("‚úÖ Foot template captured from center area");
    }

    let matchBuffer = null;

    function detect() {
      ctx.drawImage(video, 0, 0);
      if (!resizedTemplate) {
        requestAnimationFrame(detect);
        return;
      }

      const frameData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const src = cv.matFromImageData(frameData);
      const gray = new cv.Mat();
      const resized = new cv.Mat();

      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      cv.GaussianBlur(gray, gray, new cv.Size(3, 3), 0);
      cv.resize(gray, resized, new cv.Size(0, 0), scale, scale, cv.INTER_AREA);

      if (!matchBuffer || matchBuffer.rows !== (resized.rows - resizedTemplate.rows + 1) || matchBuffer.cols !== (resized.cols - resizedTemplate.cols + 1)) {
        if (matchBuffer) matchBuffer.delete();
        matchBuffer = new cv.Mat();
      }

      const result = matchBuffer;
      cv.matchTemplate(resized, resizedTemplate, result, cv.TM_CCOEFF_NORMED);
      const minMax = cv.minMaxLoc(result);
      const pt = minMax.maxLoc;
      const score = minMax.maxVal;

      if (score > minMatchScore) {
        const centerX = (pt.x + resizedTemplate.cols / 2) / scale;
        const centerY = (pt.y + resizedTemplate.rows / 2) / scale;
        drawFootDot(centerX, centerY);
        statusDiv.textContent = `üë£ Foot Detected (Score: ${score.toFixed(2)})`;
        console.log(`Foot at (${centerX}, ${centerY})`);
      } else {
        statusDiv.textContent = `üîç Scanning... (Score: ${score.toFixed(2)})`;
      }

      src.delete(); gray.delete(); resized.delete();
      requestAnimationFrame(detect);
    }

    async function main() {
      await waitForOpenCV();
      await startCamera();
      captureButton.onclick = captureTemplate;
      statusDiv.textContent = "üì∑ Align foot and press capture";
      detect();
    }

    window.addEventListener('load', main);
  </script>
</body>
</html>
